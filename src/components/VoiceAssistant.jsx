/**
 * è¯­éŸ³åŠ©æ‰‹ä¸»ç»„ä»¶
 * é›†æˆéŸ³é¢‘ç®¡ç†ã€å¯è§†åŒ–å’Œå¯¹è¯ç•Œé¢
 */

import React, { useState, useEffect, useCallback, useRef } from 'react';
import AudioManager from '../audio/AudioManager';
import AudioVisualizer from './AudioVisualizer';
import ConversationDisplay from './ConversationDisplay';
import './VoiceAssistant.css';

const VoiceAssistant = ({ 
  websocketUrl, 
  userLevel = 'intermediate',
  scenario = 'general',
  onError = null 
}) => {
  // çŠ¶æ€ç®¡ç†
  const [isInitialized, setIsInitialized] = useState(false);
  const [isRecording, setIsRecording] = useState(false);
  const [volumeLevel, setVolumeLevel] = useState(0);
  const [isSilent, setIsSilent] = useState(true);
  const [isConnected, setIsConnected] = useState(false);
  const [error, setError] = useState('');
  
  // å¯¹è¯çŠ¶æ€
  const [conversations, setConversations] = useState([]);
  const [isProcessing, setIsProcessing] = useState(false);
  const [currentTranscription, setCurrentTranscription] = useState('');
  
  // AudioManagerå®ä¾‹
  const audioManagerRef = useRef(null);
  const initializingRef = useRef(false);
  
  // åˆå§‹åŒ–éŸ³é¢‘ç®¡ç†å™¨
  const initializeAudioManager = useCallback(async () => {
    if (initializingRef.current || audioManagerRef.current?.isInitialized) {
      return;
    }
    
    try {
      initializingRef.current = true;
      setError('');
      
      console.log('Initializing VoiceAssistant...');
      
      // åˆ›å»ºAudioManagerå®ä¾‹
      audioManagerRef.current = new AudioManager();
      
      // è®¾ç½®äº‹ä»¶å›è°ƒ
      audioManagerRef.current.onVolumeLevel = (volume, silent) => {
        setVolumeLevel(volume);
        setIsSilent(silent);
      };
      
      audioManagerRef.current.onRecordingState = (recording) => {
        setIsRecording(recording);
      };
      
      audioManagerRef.current.onError = (errorMessage) => {
        setError(errorMessage);
        if (onError) onError(errorMessage);
      };
      
      // åˆå§‹åŒ–éŸ³é¢‘ç³»ç»Ÿ
      const audioInitialized = await audioManagerRef.current.initialize();
      if (!audioInitialized) {
        throw new Error('éŸ³é¢‘ç³»ç»Ÿåˆå§‹åŒ–å¤±è´¥');
      }
      
      // è¿æ¥WebSocket
      if (websocketUrl) {
        const wsConnected = await audioManagerRef.current.connectWebSocket(websocketUrl);
        setIsConnected(wsConnected);
      }
      
      setIsInitialized(true);
      console.log('VoiceAssistant initialized successfully');
      
    } catch (error) {
      console.error('VoiceAssistant initialization failed:', error);
      setError(error.message);
      if (onError) onError(error.message);
    } finally {
      initializingRef.current = false;
    }
  }, [websocketUrl, onError]);
  
  // å¼€å§‹å½•éŸ³
  const startRecording = useCallback(async () => {
    if (!audioManagerRef.current?.isInitialized) {
      await initializeAudioManager();
    }
    
    try {
      await audioManagerRef.current.startRecording();
      setCurrentTranscription('æ­£åœ¨å¬å–æ‚¨çš„è¯­éŸ³...');
      setIsProcessing(false);
    } catch (error) {
      console.error('Start recording failed:', error);
      setError('å¼€å§‹å½•éŸ³å¤±è´¥: ' + error.message);
    }
  }, [initializeAudioManager]);
  
  // åœæ­¢å½•éŸ³
  const stopRecording = useCallback(() => {
    if (audioManagerRef.current && isRecording) {
      audioManagerRef.current.stopRecording();
      setCurrentTranscription('æ­£åœ¨å¤„ç†è¯­éŸ³...');
      setIsProcessing(true);
    }
  }, [isRecording]);
  
  // åˆ‡æ¢å½•éŸ³çŠ¶æ€
  const toggleRecording = useCallback(async () => {
    if (isRecording) {
      stopRecording();
    } else {
      await startRecording();
    }
  }, [isRecording, startRecording, stopRecording]);
  
  // å¤„ç†WebSocketæ¶ˆæ¯
  useEffect(() => {
    if (!audioManagerRef.current) return;
    
    // é‡å†™WebSocketæ¶ˆæ¯å¤„ç†
    const originalHandler = audioManagerRef.current.handleWebSocketMessage.bind(audioManagerRef.current);
    
    audioManagerRef.current.handleWebSocketMessage = (event) => {
      try {
        // å¤„ç†äºŒè¿›åˆ¶éŸ³é¢‘æ•°æ®
        if (event.data instanceof ArrayBuffer) {
          originalHandler(event);
          return;
        }
        
        // å¤„ç†JSONæ¶ˆæ¯
        const message = JSON.parse(event.data);
        console.log('Received message:', message);
        
        switch (message.type) {
          case 'transcription':
            setCurrentTranscription(message.text || '');
            setConversations(prev => [
              ...prev,
              {
                id: Date.now(),
                type: 'user',
                text: message.text,
                timestamp: new Date(),
                analysis: message.analysis
              }
            ]);
            break;
            
          case 'ai_response':
            setIsProcessing(false);
            setCurrentTranscription('');
            setConversations(prev => [
              ...prev,
              {
                id: Date.now() + 1,
                type: 'assistant',
                text: message.text,
                timestamp: new Date(),
                metadata: message.metadata
              }
            ]);
            
            // æ’­æ”¾AIå›å¤éŸ³é¢‘
            if (message.audio) {
              audioManagerRef.current.playAudio(message.audio).catch(error => {
                console.error('Play AI audio failed:', error);
              });
            }
            break;
            
          case 'error':
            setIsProcessing(false);
            setCurrentTranscription('');
            setError('æœåŠ¡å™¨é”™è¯¯: ' + message.error);
            break;
            
          default:
            originalHandler(event);
        }
      } catch (error) {
        console.error('Handle WebSocket message failed:', error);
        originalHandler(event);
      }
    };
  }, []);
  
  // æ¸…é™¤é”™è¯¯
  const clearError = useCallback(() => {
    setError('');
  }, []);
  
  // æ¸…é™¤å¯¹è¯å†å²
  const clearConversations = useCallback(() => {
    setConversations([]);
    setCurrentTranscription('');
  }, []);
  
  // ç»„ä»¶å¸è½½æ—¶æ¸…ç†èµ„æº
  useEffect(() => {
    return () => {
      if (audioManagerRef.current) {
        audioManagerRef.current.destroy();
        audioManagerRef.current = null;
      }
    };
  }, []);
  
  // è‡ªåŠ¨åˆå§‹åŒ–
  useEffect(() => {
    if (!isInitialized && !initializingRef.current) {
      initializeAudioManager();
    }
  }, [isInitialized, initializeAudioManager]);
  
  return (
    <div className="voice-assistant">
      <div className="assistant-header">
        <h2 className="assistant-title">
          <span className="title-icon">ğŸ¤</span>
          AIè¯­éŸ³åŠ©æ‰‹
        </h2>
        <div className="connection-status">
          <div className={`status-dot ${isConnected ? 'connected' : 'disconnected'}`}></div>
          <span className="status-text">
            {isConnected ? 'å·²è¿æ¥' : 'æœªè¿æ¥'}
          </span>
        </div>
      </div>
      
      {/* é”™è¯¯æç¤º */}
      {error && (
        <div className="error-banner">
          <div className="error-content">
            <span className="error-icon">âš ï¸</span>
            <span className="error-text">{error}</span>
            <button 
              className="error-close"
              onClick={clearError}
              aria-label="å…³é—­é”™è¯¯æç¤º"
            >
              Ã—
            </button>
          </div>
        </div>
      )}
      
      {/* éŸ³é¢‘å¯è§†åŒ– */}
      <div className="visualizer-section">
        <AudioVisualizer
          volumeLevel={volumeLevel}
          isRecording={isRecording}
          isSilent={isSilent}
        />
      </div>
      
      {/* å½“å‰è½¬å½•å†…å®¹ */}
      {currentTranscription && (
        <div className="transcription-display">
          <div className={`transcription-content ${isProcessing ? 'processing' : ''}`}>
            {isProcessing && <div className="processing-spinner"></div>}
            <span className="transcription-text">{currentTranscription}</span>
          </div>
        </div>
      )}
      
      {/* æ§åˆ¶æŒ‰é’® */}
      <div className="control-section">
        <button
          className={`record-button ${isRecording ? 'recording' : 'idle'}`}
          onClick={toggleRecording}
          disabled={!isInitialized || isProcessing}
          aria-label={isRecording ? 'åœæ­¢å½•éŸ³' : 'å¼€å§‹å½•éŸ³'}
        >
          <div className="record-button-inner">
            {isRecording ? (
              <div className="stop-icon"></div>
            ) : (
              <div className="mic-icon">ğŸ¤</div>
            )}
          </div>
          <span className="record-button-text">
            {isRecording ? 'åœæ­¢å½•éŸ³' : 'å¼€å§‹å¯¹è¯'}
          </span>
        </button>
        
        <div className="secondary-controls">
          <button
            className="control-button"
            onClick={clearConversations}
            disabled={conversations.length === 0}
            aria-label="æ¸…é™¤å¯¹è¯å†å²"
          >
            <span className="control-icon">ğŸ—‘ï¸</span>
            æ¸…é™¤å†å²
          </button>
          
          <div className="settings-info">
            <span className="setting-item">ç­‰çº§: {userLevel}</span>
            <span className="setting-item">åœºæ™¯: {scenario}</span>
          </div>
        </div>
      </div>
      
      {/* å¯¹è¯å†å² */}
      <div className="conversation-section">
        <ConversationDisplay
          conversations={conversations}
          isProcessing={isProcessing}
        />
      </div>
    </div>
  );
};

export default VoiceAssistant;