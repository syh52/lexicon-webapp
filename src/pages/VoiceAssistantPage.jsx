import React, { useState, useRef, useEffect } from 'react';
import { Mic, MicOff, Volume2, VolumeX, Play, Square, Settings, Sparkles, MessageCircle, Brain, Headphones, RotateCcw } from 'lucide-react';
import { getApp, ensureLogin, getCachedLoginState, startKeepAlive, stopKeepAlive, updateActivity } from '../utils/cloudbase';
import { startWarmup, startKeepAlive as startFunctionKeepAlive, stopKeepAlive as stopFunctionKeepAlive, smartWarmup } from '../utils/functionKeepAlive';
import { getCachedTTS, cacheTTS } from '../utils/ttsCache';
import { createConcurrentProcessor, PROCESSING_STAGES } from '../utils/concurrentProcessor';
import { ttsConfig } from '../config/voiceConfig';
import AudioRecorder from '../utils/audioRecorder';
import RealtimeVoiceAssistant from '../components/RealtimeVoiceAssistant';

const VoiceAssistantPage = () => {
  // è¯­éŸ³åŠ©æ‰‹æ¨¡å¼é€‰æ‹©ï¼š'classic' æˆ– 'realtime'
  const [assistantMode, setAssistantMode] = useState('realtime');
  const [isConnected, setIsConnected] = useState(false);
  const [isRecording, setIsRecording] = useState(false);
  const [isPlaying, setIsPlaying] = useState(false);
  const [messages, setMessages] = useState([]);
  const [status, setStatus] = useState('disconnected');
  const [currentTranscript, setCurrentTranscript] = useState('');
  const [isSupported, setIsSupported] = useState(true);
  const [error, setError] = useState('');
  const [isAIProcessing, setIsAIProcessing] = useState(false);
  const [currentModel, setCurrentModel] = useState('gpt-4o-mini');
  const [currentVoice, setCurrentVoice] = useState('alloy');
  const [authState, setAuthState] = useState('disconnected');

  // å¹¶å‘å¤„ç†ç›¸å…³çŠ¶æ€
  const [processingStage, setProcessingStage] = useState(null);
  const [processingProgress, setProcessingProgress] = useState(0);
  const [isUsingConcurrentMode, setIsUsingConcurrentMode] = useState(true);

  // AIæ¨¡å‹é€‰é¡¹ï¼ˆä¸è®¾ç½®é¡µé¢ä¿æŒä¸€è‡´ï¼‰
  const AI_MODELS = [
    { value: 'o3-mini', label: 'O3-Mini' },
    { value: 'chatgpt-4o-latest', label: 'ChatGPT-4o Latest' },
    { value: 'gpt-4.1', label: 'GPT-4.1' },
    { value: 'gpt-4.1-nano', label: 'GPT-4.1 Nano' },
    { value: 'gpt-4o-mini', label: 'GPT-4o Mini' }
  ];

  // AIåŠ©æ‰‹å£°éŸ³é€‰é¡¹ï¼ˆä¸è®¾ç½®é¡µé¢ä¿æŒä¸€è‡´ï¼‰
  const VOICE_OPTIONS = [
    { value: 'alloy', label: 'Alloy', description: 'ä¸­æ€§ï¼Œæ¸…æ™°' },
    { value: 'echo', label: 'Echo', description: 'ç”·æ€§ï¼Œæ¸©å’Œ' },
    { value: 'fable', label: 'Fable', description: 'è‹±å¼ï¼Œä¼˜é›…' },
    { value: 'onyx', label: 'Onyx', description: 'ç”·æ€§ï¼Œæ·±æ²‰' },
    { value: 'nova', label: 'Nova', description: 'å¥³æ€§ï¼Œæ´»æ³¼' },
    { value: 'shimmer', label: 'Shimmer', description: 'å¥³æ€§ï¼Œæ¸©æŸ”' }
  ];
  const [userLevel, setUserLevel] = useState('intermediate');
  const [scenario, setScenario] = useState('general');
  const [isTestingAPI, setIsTestingAPI] = useState(false);
  const [apiTestResult, setApiTestResult] = useState(null);
  const [microphonePermission, setMicrophonePermission] = useState('unknown');
  const [isProcessingAudio, setIsProcessingAudio] = useState(false);
  const [showSettings, setShowSettings] = useState(false);
  const [replayingMessageId, setReplayingMessageId] = useState(null);

  const audioRecorderRef = useRef(null);
  const concurrentProcessorRef = useRef(null);

  // åˆå§‹åŒ–å¹¶å‘å¤„ç†å™¨
  useEffect(() => {
    if (isUsingConcurrentMode) {
      concurrentProcessorRef.current = createConcurrentProcessor({
        feedbackCallbacks: {
          onStageUpdate: (stage, description) => {
            setProcessingStage(stage);
            setCurrentTranscript(description);
          },
          onProgressUpdate: (progress) => {
            setProcessingProgress(progress);
          },
          onPartialResult: (partialData) => {
            console.log('ğŸ“¦ æ”¶åˆ°éƒ¨åˆ†ç»“æœ:', partialData);
            if (partialData.stage === PROCESSING_STAGES.SPEECH_RECOGNITION) {
              // è¯­éŸ³è¯†åˆ«å®Œæˆï¼Œæ·»åŠ ç”¨æˆ·æ¶ˆæ¯
              const userMessage = {
                id: Date.now(),
                type: 'user', 
                content: partialData.result,
                timestamp: new Date().toLocaleTimeString()
              };
              setMessages(prev => [...prev, userMessage]);
            }
          },
          onError: (error) => {
            setError(`å¤„ç†å¤±è´¥: ${error.message}`);
            setProcessingStage(null);
            setProcessingProgress(0);
          },
          onComplete: () => {
            setProcessingStage(null);
            setProcessingProgress(0);
            setCurrentTranscript('');
          }
        },
        speechRecognizer: handleSpeechRecognitionCore,
        aiResponder: handleAIResponseCore,
        ttsGenerator: handleTextToSpeech
      });
    }
  }, [isUsingConcurrentMode, userLevel, scenario, currentModel]);

  // åŠ è½½ç”¨æˆ·è®¾ç½®
  useEffect(() => {
    const savedModel = localStorage.getItem('ai-model') || 'gpt-4o-mini';
    const savedVoice = localStorage.getItem('ai-voice') || 'alloy';
    setCurrentModel(savedModel);
    setCurrentVoice(savedVoice);
  }, []);

  // ç›‘å¬localStorageå˜åŒ–ï¼Œå®æ—¶æ›´æ–°è®¾ç½®
  useEffect(() => {
    const handleStorageChange = () => {
      const savedModel = localStorage.getItem('ai-model') || 'gpt-4o-mini';
      const savedVoice = localStorage.getItem('ai-voice') || 'alloy';
      setCurrentModel(savedModel);
      setCurrentVoice(savedVoice);
    };

    // ç›‘å¬storageäº‹ä»¶ï¼ˆè·¨æ ‡ç­¾é¡µï¼‰
    window.addEventListener('storage', handleStorageChange);
    
    // ç›‘å¬è‡ªå®šä¹‰äº‹ä»¶ï¼ˆåŒä¸€æ ‡ç­¾é¡µå†…çš„å˜åŒ–ï¼‰
    window.addEventListener('settingsChanged', handleStorageChange);

    return () => {
      window.removeEventListener('storage', handleStorageChange);
      window.removeEventListener('settingsChanged', handleStorageChange);
    };
  }, []);

  // åˆå§‹åŒ–CloudBaseè®¤è¯ï¼ˆä½¿ç”¨ç»Ÿä¸€çš„å•ä¾‹å®ä¾‹ï¼‰
  useEffect(() => {
    const initAuth = async () => {
      try {
        console.log('ğŸ”„ VoiceAssistant: åˆå§‹åŒ–è®¤è¯...');
        setAuthState('connecting');
        
        // ç¡®ä¿ç™»å½•çŠ¶æ€
        const loginState = await ensureLogin();
        
        if (loginState && loginState.isLoggedIn) {
          console.log('âœ… VoiceAssistant: è®¤è¯æˆåŠŸ');
          setAuthState('connected');
          setError(''); // æ¸…é™¤ä¹‹å‰çš„é”™è¯¯
          
          // å¯åŠ¨è¿æ¥ä¿æ´»æœºåˆ¶
          startKeepAlive();
          
          // å¯åŠ¨äº‘å‡½æ•°é¢„çƒ­å’Œä¿æ´»
          console.log('ğŸ”¥ å¯åŠ¨äº‘å‡½æ•°é¢„çƒ­æœºåˆ¶...');
          startWarmup(); // é¢„çƒ­å…³é”®å‡½æ•°
          startFunctionKeepAlive(); // å¯åŠ¨å‡½æ•°ä¿æ´»
        } else {
          console.log('âŒ VoiceAssistant: è®¤è¯å¤±è´¥');
          setAuthState('error');
          setError('CloudBaseè®¤è¯å¤±è´¥ï¼ŒAIåŠŸèƒ½å¯èƒ½æ— æ³•æ­£å¸¸ä½¿ç”¨');
        }
      } catch (error) {
        console.error('âŒ VoiceAssistant: è®¤è¯å¼‚å¸¸:', error);
        setAuthState('error');
        setError(`CloudBaseè¿æ¥å¤±è´¥ï¼š${error.message}`);
      }
    };
    
    initAuth();
    
    // æ¸…ç†å‡½æ•°ï¼šç»„ä»¶å¸è½½æ—¶åœæ­¢ä¿æ´»
    return () => {
      stopKeepAlive();
      stopFunctionKeepAlive();
    };
  }, []);

  // æ£€æŸ¥éº¦å…‹é£æƒé™
  useEffect(() => {
    const checkMicrophonePermission = async () => {
      try {
        if (navigator.permissions) {
          const permission = await navigator.permissions.query({ name: 'microphone' });
          setMicrophonePermission(permission.state);
          
          // ç›‘å¬æƒé™å˜åŒ–
          permission.onchange = () => {
            setMicrophonePermission(permission.state);
          };
        } else {
          setMicrophonePermission('unknown');
        }
      } catch (error) {
        console.log('æ— æ³•æ£€æŸ¥éº¦å…‹é£æƒé™:', error);
        setMicrophonePermission('unknown');
      }
    };

    checkMicrophonePermission();
  }, []);

  // è¯·æ±‚éº¦å…‹é£æƒé™
  const requestMicrophonePermission = async () => {
    try {
      const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
      
      // æƒé™è·å–æˆåŠŸ
      setMicrophonePermission('granted');
      setError('');
      
      // å…³é—­æµ
      stream.getTracks().forEach(track => track.stop());
      
      return true;
    } catch (error) {
      console.error('éº¦å…‹é£æƒé™è¯·æ±‚å¤±è´¥:', error);
      setMicrophonePermission('denied');
      
      let errorMessage = 'éº¦å…‹é£æƒé™è¢«æ‹’ç»';
      if (error.name === 'NotAllowedError') {
        errorMessage = 'éº¦å…‹é£æƒé™è¢«æ‹’ç»ã€‚è¯·åœ¨æµè§ˆå™¨è®¾ç½®ä¸­å…è®¸éº¦å…‹é£æƒé™ã€‚';
      } else if (error.name === 'NotFoundError') {
        errorMessage = 'æœªæ‰¾åˆ°éº¦å…‹é£è®¾å¤‡ã€‚è¯·æ£€æŸ¥éº¦å…‹é£æ˜¯å¦å·²è¿æ¥ã€‚';
      } else if (error.name === 'NotSupportedError') {
        errorMessage = 'æµè§ˆå™¨ä¸æ”¯æŒéº¦å…‹é£åŠŸèƒ½ã€‚';
      }
      
      setError(errorMessage + '\nğŸ’¡ æç¤ºï¼šç‚¹å‡»åœ°å€æ å·¦ä¾§çš„é”å›¾æ ‡ â†’ éº¦å…‹é£ â†’ å…è®¸');
      return false;
    }
  };

  // åˆå§‹åŒ–éŸ³é¢‘å½•åˆ¶å™¨
  useEffect(() => {
    const initAudioRecorder = async () => {
      try {
        // æ£€æŸ¥æµè§ˆå™¨æ”¯æŒ
        if (!AudioRecorder.isSupported()) {
          setIsSupported(false);
          setError('æ‚¨çš„æµè§ˆå™¨ä¸æ”¯æŒéŸ³é¢‘å½•åˆ¶ï¼Œè¯·ä½¿ç”¨Chromeæµè§ˆå™¨');
          return;
        }

        // åˆ›å»ºå½•éŸ³å™¨å®ä¾‹
        const recorder = new AudioRecorder();
        
        // è®¾ç½®äº‹ä»¶å¤„ç†å™¨
        recorder.onStart = () => {
          console.log('ğŸ™ï¸ å¼€å§‹å½•éŸ³');
          setIsRecording(true);
          setStatus('recording');
          setCurrentTranscript('æ­£åœ¨å½•éŸ³ä¸­...');
          setError('');
        };

        recorder.onStop = async (audioData) => {
          console.log('ğŸ›‘ å½•éŸ³ç»“æŸï¼Œå¼€å§‹å¤„ç†...');
          setIsRecording(false);
          setStatus(isConnected ? 'connected' : 'disconnected');
          setIsProcessingAudio(true);

          try {
            if (isUsingConcurrentMode && concurrentProcessorRef.current) {
              // ä½¿ç”¨å¹¶å‘å¤„ç†å™¨å¤„ç†è¯­éŸ³è¾“å…¥
              console.log('ğŸš€ å¯åŠ¨å¹¶å‘å¤„ç†æ¨¡å¼');
              await concurrentProcessorRef.current.processVoiceInput(audioData);
            } else {
              // ä¼ ç»Ÿä¸²è¡Œå¤„ç†æ¨¡å¼
              console.log('ğŸ”„ ä½¿ç”¨ä¼ ç»Ÿä¸²è¡Œå¤„ç†æ¨¡å¼');
              setCurrentTranscript('æ­£åœ¨è¯†åˆ«è¯­éŸ³...');
              await handleSpeechRecognition(audioData);
            }
          } catch (error) {
            console.error('âŒ è¯­éŸ³å¤„ç†å¤±è´¥:', error);
            setError(`è¯­éŸ³å¤„ç†å¤±è´¥: ${error.message}`);
          } finally {
            setIsProcessingAudio(false);
            if (!isUsingConcurrentMode) {
              setCurrentTranscript('');
            }
          }
        };

        recorder.onError = (error) => {
          console.error('âŒ å½•éŸ³é”™è¯¯:', error);
          setIsRecording(false);
          setStatus(isConnected ? 'connected' : 'disconnected');
          setCurrentTranscript('');
          setError(`å½•éŸ³å¤±è´¥: ${error.message}`);
        };

        // å°è¯•åˆå§‹åŒ–å½•éŸ³å™¨
        await recorder.initialize();
        audioRecorderRef.current = recorder;
        setIsSupported(true);
        
        console.log('âœ… éŸ³é¢‘å½•åˆ¶å™¨åˆå§‹åŒ–æˆåŠŸ');

      } catch (error) {
        console.error('âŒ éŸ³é¢‘å½•åˆ¶å™¨åˆå§‹åŒ–å¤±è´¥:', error);
        setIsSupported(false);
        setError(`éŸ³é¢‘å½•åˆ¶å™¨åˆå§‹åŒ–å¤±è´¥: ${error.message}`);
      }
    };

    initAudioRecorder();

    // æ¸…ç†å‡½æ•°
    return () => {
      if (audioRecorderRef.current) {
        audioRecorderRef.current.destroy();
      }
    };
  }, []);

  // æ ¸å¿ƒè¯­éŸ³è¯†åˆ«å‡½æ•°ï¼ˆç”¨äºå¹¶å‘å¤„ç†å™¨ï¼‰
  const handleSpeechRecognitionCore = async (audioData) => {
    console.log('ğŸ”„ æ ¸å¿ƒè¯­éŸ³è¯†åˆ«å¼€å§‹');
    
    updateActivity();
    const app = getApp();
    
    const formatInfo = audioRecorderRef.current?.getAudioFormat();
    
    // ç®€åŒ–ç‰ˆæœ¬çš„è¯­éŸ³è¯†åˆ«ï¼Œä¸“æ³¨äºæ ¸å¿ƒé€»è¾‘
    const result = await app.callFunction({
      name: 'speech-recognition',
      data: {
        audioData: audioData.base64Audio,
        language: 'auto',
        format: formatInfo?.format || 'webm',
        response_format: 'json',
        temperature: 0
      },
      timeout: 45000
    });

    if (result.result && result.result.success && result.result.text) {
      return result.result.text.trim();
    } else {
      const errorInfo = result.result?.error;
      throw new Error(typeof errorInfo === 'string' ? errorInfo : 'è¯­éŸ³è¯†åˆ«å¤±è´¥');
    }
  };

  // æ ¸å¿ƒAIå“åº”å‡½æ•°ï¼ˆç”¨äºå¹¶å‘å¤„ç†å™¨ï¼‰
  const handleAIResponseCore = async (userInput) => {
    console.log('ğŸ¤– æ ¸å¿ƒAIå“åº”å¼€å§‹');
    
    updateActivity();
    const app = getApp();

    const result = await app.callFunction({
      name: 'ai-chat',
      data: {
        messages: [{ role: 'user', content: userInput }],
        userLevel: userLevel,
        scenario: scenario,
        model: currentModel
      },
      timeout: 60000
    });

    if (result.result && result.result.success && result.result.response) {
      const aiResponse = result.result.response.trim();
      
      // æ·»åŠ AIæ¶ˆæ¯åˆ°å¯¹è¯è®°å½•
      const aiMessage = {
        id: Date.now() + 1,
        type: 'assistant',
        content: aiResponse,
        timestamp: new Date().toLocaleTimeString(),
        model: currentModel,
        method: result.result.method
      };
      setMessages(prev => [...prev, aiMessage]);

      return aiResponse;
    } else {
      const errorMsg = result.result?.error || 'AIæœåŠ¡å¤±è´¥';
      throw new Error(errorMsg);
    }
  };

  // å¤„ç†è¯­éŸ³è¯†åˆ« - è°ƒç”¨ OpenAI Whisper API
  const handleSpeechRecognition = async (audioData) => {
    console.log('ğŸ”„ å¼€å§‹è°ƒç”¨ OpenAI Whisper API è¿›è¡Œè¯­éŸ³è¯†åˆ«');
    
    try {
      // æ›´æ–°æ´»åŠ¨æ—¶é—´æˆ³ï¼ˆç§»é™¤é‡å¤çš„è®¤è¯è°ƒç”¨ï¼‰
      updateActivity();
      const app = getApp();

      // è·å–éŸ³é¢‘æ ¼å¼ä¿¡æ¯
      const formatInfo = audioRecorderRef.current?.getAudioFormat();
      console.log('ğŸ“¦ éŸ³é¢‘æ•°æ®ä¿¡æ¯:', {
        size: audioData.size,
        type: audioData.mimeType,
        format: formatInfo?.format || 'webm'
      });

      // è°ƒç”¨ speech-recognition äº‘å‡½æ•°ï¼ˆå¢åŠ é‡è¯•æœºåˆ¶ï¼‰
      let result;
      let lastError;
      
      for (let attempt = 1; attempt <= 2; attempt++) {
        try {
          console.log(`ğŸ”„ å°è¯•ç¬¬ ${attempt} æ¬¡è°ƒç”¨è¯­éŸ³è¯†åˆ«...`);
          
          result = await app.callFunction({
            name: 'speech-recognition',
            data: {
              audioData: audioData.base64Audio,
              language: 'auto', // è‡ªåŠ¨æ£€æµ‹è¯­è¨€ï¼Œæ”¯æŒä¸­è‹±æ··åˆ
              format: formatInfo?.format || 'webm',
              response_format: 'json',
              temperature: 0
            },
            timeout: 45000 // 45ç§’è¶…æ—¶
          });
          
          // å¦‚æœæˆåŠŸï¼Œè·³å‡ºé‡è¯•å¾ªç¯
          break;
          
        } catch (attemptError) {
          console.error(`âŒ ç¬¬ ${attempt} æ¬¡å°è¯•å¤±è´¥:`, attemptError);
          lastError = attemptError;
          
          // å¦‚æœä¸æ˜¯æœ€åä¸€æ¬¡å°è¯•ï¼Œç­‰å¾…åé‡è¯•
          if (attempt < 2) {
            console.log('â³ ç­‰å¾… 2 ç§’åé‡è¯•...');
            await new Promise(resolve => setTimeout(resolve, 2000));
          }
        }
      }
      
      // å¦‚æœæ‰€æœ‰å°è¯•éƒ½å¤±è´¥äº†
      if (!result) {
        const errorMessage = lastError?.message || 'unknown error';
        console.error('ğŸ’¥ æ‰€æœ‰é‡è¯•å°è¯•éƒ½å¤±è´¥äº†:', errorMessage);
        
        // æ ¹æ®é”™è¯¯ç±»å‹æä¾›æ›´å…·ä½“çš„é”™è¯¯ä¿¡æ¯
        if (errorMessage.includes('timeout')) {
          throw new Error('è¯­éŸ³è¯†åˆ«æœåŠ¡å“åº”è¶…æ—¶ï¼Œè¯·æ£€æŸ¥ç½‘ç»œè¿æ¥æˆ–ç¨åé‡è¯•');
        } else if (errorMessage.includes('network')) {
          throw new Error('ç½‘ç»œè¿æ¥é”™è¯¯ï¼Œè¯·æ£€æŸ¥ç½‘ç»œè®¾ç½®');
        } else {
          throw new Error(`è¯­éŸ³è¯†åˆ«æœåŠ¡æš‚æ—¶ä¸å¯ç”¨: ${errorMessage}`);
        }
      }

      console.log('ğŸ“¥ è¯­éŸ³è¯†åˆ«ç»“æœ:', {
        success: result.result?.success,
        method: result.result?.method,
        textLength: result.result?.text?.length || 0,
        hasError: !!result.result?.error
      });

      if (result.result && result.result.success && result.result.text) {
        const recognizedText = result.result.text.trim();
        console.log('âœ… è¯†åˆ«æˆåŠŸ:', recognizedText);

        // æ·»åŠ ç”¨æˆ·æ¶ˆæ¯åˆ°å¯¹è¯è®°å½•
        const userMessage = {
          id: Date.now(),
          type: 'user',
          content: recognizedText,
          timestamp: new Date().toLocaleTimeString(),
          method: result.result.method,
          duration: result.result.duration
        };
        setMessages(prev => [...prev, userMessage]);

        // è°ƒç”¨AIæœåŠ¡ç”Ÿæˆå›å¤
        await handleAIResponse(recognizedText);

      } else {
        // å¤„ç†äº‘å‡½æ•°è¿”å›çš„é”™è¯¯
        const errorInfo = result.result?.error;
        let errorMsg = 'è¯­éŸ³è¯†åˆ«å¤±è´¥';
        
        if (typeof errorInfo === 'object' && errorInfo.message) {
          errorMsg = errorInfo.message;
        } else if (typeof errorInfo === 'string') {
          errorMsg = errorInfo;
        }
        
        console.error('âŒ è¯­éŸ³è¯†åˆ«å¤±è´¥:', errorMsg);
        throw new Error(errorMsg);
      }

    } catch (error) {
      console.error('ğŸ’¥ è¯­éŸ³è¯†åˆ«å¼‚å¸¸:', error);
      
      // æ›´å‹å¥½çš„é”™è¯¯æç¤º
      const friendlyMessage = error.message.includes('network') 
        ? 'ç½‘ç»œè¿æ¥å¼‚å¸¸ï¼Œè¯·æ£€æŸ¥ç½‘ç»œè®¾ç½®åé‡è¯•'
        : error.message;
        
      throw new Error(friendlyMessage);
    }
  };

  // è°ƒç”¨AIæœåŠ¡ç”Ÿæˆå›å¤
  const handleAIResponse = async (userInput) => {
    setIsAIProcessing(true);
    
    try {
      console.log('ğŸ”„ VoiceAssistant: å¼€å§‹è°ƒç”¨AIæœåŠ¡:', {
        userInput: userInput.substring(0, 100) + (userInput.length > 100 ? '...' : ''),
        userLevel,
        scenario,
        model: currentModel,
        authState
      });

      // æ›´æ–°æ´»åŠ¨æ—¶é—´æˆ³ï¼ˆç§»é™¤é‡å¤çš„è®¤è¯è°ƒç”¨ï¼‰
      updateActivity();
      const app = getApp();

      // è°ƒç”¨ai-chatäº‘å‡½æ•°ï¼ˆå¢åŠ è¶…æ—¶è®¾ç½®ï¼‰
      const result = await app.callFunction({
        name: 'ai-chat',
        data: {
          messages: [
            {
              role: 'user',
              content: userInput
            }
          ],
          userLevel: userLevel,
          scenario: scenario,
          model: currentModel
        },
        timeout: 60000 // 60ç§’è¶…æ—¶ï¼Œé€‚åº”é«˜çº§æ¨¡å‹çš„å“åº”æ—¶é—´
      });

      console.log('ğŸ“¥ äº‘å‡½æ•°è°ƒç”¨ç»“æœ:', {
        success: result.result?.success,
        hasResponse: !!result.result?.response,
        method: result.result?.method,
        error: result.result?.error,
        errorType: result.result?.errorType,
        executionTime: result.result?.executionTime
      });

      if (result.result && result.result.success) {
        const aiResponse = result.result.response;
        const method = result.result.method;
        const executionTime = result.result.executionTime;
        
        console.log('âœ… AIå›å¤æˆåŠŸ:', {
          responseLength: aiResponse?.length,
          method,
          executionTime
        });
        
        // æ·»åŠ AIæ¶ˆæ¯åˆ°å¯¹è¯è®°å½•
        const aiMessage = {
          id: Date.now() + 1,
          type: 'assistant',
          content: aiResponse,
          timestamp: new Date().toLocaleTimeString(),
          method: method,
          executionTime
        };
        setMessages(prev => [...prev, aiMessage]);
        
        // è¯­éŸ³åˆæˆæ’­æ”¾AIå›å¤ - ä½¿ç”¨äº‘å‡½æ•°TTSæœåŠ¡ï¼ˆä¼˜å…ˆï¼‰
        await handleTextToSpeech(aiResponse);
        
        // æ¸…é™¤ä¹‹å‰çš„é”™è¯¯
        setError('');
      } else {
        // å¤„ç†äº‘å‡½æ•°è¿”å›çš„é”™è¯¯
        const errorMsg = result.result?.error || 'è°ƒç”¨AIæœåŠ¡å¤±è´¥';
        const errorType = result.result?.errorType || 'UnknownError';
        const executionTime = result.result?.executionTime;
        
        console.error('âŒ AIæœåŠ¡è¿”å›é”™è¯¯:', {
          error: errorMsg,
          errorType,
          executionTime
        });
        
        // æ˜¾ç¤ºè¯¦ç»†çš„é”™è¯¯ä¿¡æ¯
        let displayError = `AIæœåŠ¡é”™è¯¯: ${errorMsg}`;
        if (executionTime) {
          displayError += ` (${executionTime}ms)`;
        }
        
        // æ ¹æ®é”™è¯¯ç±»å‹ç»™å‡ºç‰¹å®šæç¤º
        if (errorMsg.includes('APIå¯†é’¥')) {
          displayError += '\nğŸ’¡ è¯·æ£€æŸ¥CloudBaseæ§åˆ¶å°ä¸­çš„API_KEYç¯å¢ƒå˜é‡é…ç½®';
        } else if (errorMsg.includes('ç½‘ç»œè¯·æ±‚å¤±è´¥')) {
          displayError += '\nğŸ’¡ ç½‘ç»œè¿æ¥é—®é¢˜ï¼Œè¯·æ£€æŸ¥ç½‘ç»œæˆ–ç¨åé‡è¯•';
        } else if (errorMsg.includes('çŠ¶æ€ç ')) {
          displayError += '\nğŸ’¡ APIæœåŠ¡è¿”å›å¼‚å¸¸ï¼Œè¯·æ£€æŸ¥APIé…ç½®æˆ–è”ç³»æœåŠ¡æä¾›å•†';
        } else if (errorMsg.includes('æ ¼å¼é”™è¯¯') || errorMsg.includes('è§£æå¤±è´¥')) {
          displayError += '\nğŸ’¡ APIå“åº”æ ¼å¼å¼‚å¸¸ï¼Œå¯èƒ½æ˜¯æ¨¡å‹ä¸æ”¯æŒæˆ–å‚æ•°é”™è¯¯';
        }
        
        setError(displayError);
        throw new Error(errorMsg);
      }
    } catch (error) {
      console.error('ğŸ’¥ AIæœåŠ¡è°ƒç”¨å¼‚å¸¸:', error);
      
      // ç›´æ¥æ˜¾ç¤ºçœŸå®é”™è¯¯ï¼Œä¸ä½¿ç”¨ä»»ä½•å‡å›å¤æˆ–é™çº§æœºåˆ¶
      let detailedError = `ğŸ”¥ AIæœåŠ¡è°ƒç”¨å¤±è´¥: ${error.message}`;
      
      // æä¾›å…·ä½“çš„æ•…éšœæ’é™¤å»ºè®®
      if (error.message.includes('ç½‘ç»œ') || error.message.includes('network')) {
        detailedError += '\n\nğŸ”§ è§£å†³å»ºè®®:\nâ€¢ æ£€æŸ¥ç½‘ç»œè¿æ¥\nâ€¢ éªŒè¯APIæœåŠ¡çŠ¶æ€\nâ€¢ ç¡®è®¤API Base URLé…ç½®';
      } else if (error.message.includes('è¶…æ—¶') || error.message.includes('timeout')) {
        detailedError += '\n\nğŸ”§ è§£å†³å»ºè®®:\nâ€¢ APIå“åº”è¶…æ—¶ï¼Œå¯èƒ½æ˜¯æ¨¡å‹è¾ƒæ…¢\nâ€¢ å°è¯•åˆ‡æ¢åˆ°æ›´å¿«çš„æ¨¡å‹(å¦‚gpt-4o-mini)\nâ€¢ æ£€æŸ¥APIæœåŠ¡è´Ÿè½½çŠ¶å†µ';
      } else if (error.message.includes('401')) {
        detailedError += '\n\nğŸ”§ è§£å†³å»ºè®®:\nâ€¢ APIå¯†é’¥æ— æ•ˆæˆ–å·²è¿‡æœŸ\nâ€¢ åœ¨CloudBaseæ§åˆ¶å°æ›´æ–°API_KEYç¯å¢ƒå˜é‡';
      } else {
        detailedError += '\n\nğŸ”§ è§£å†³å»ºè®®:\nâ€¢ æ£€æŸ¥CloudBaseæ§åˆ¶å°æ—¥å¿—\nâ€¢ éªŒè¯APIé…ç½®\nâ€¢ è”ç³»æŠ€æœ¯æ”¯æŒ';
      }
      
      setError(detailedError);
    } finally {
      setIsAIProcessing(false);
    }
  };

  const handleStartRecording = async () => {
    if (!isSupported || !audioRecorderRef.current) {
      setError('éŸ³é¢‘å½•åˆ¶ä¸å¯ç”¨');
      return;
    }

    // æ£€æŸ¥éº¦å…‹é£æƒé™
    if (microphonePermission === 'denied') {
      setError('éº¦å…‹é£æƒé™è¢«æ‹’ç»ã€‚è¯·åœ¨æµè§ˆå™¨è®¾ç½®ä¸­å…è®¸éº¦å…‹é£æƒé™ã€‚\nğŸ’¡ æç¤ºï¼šç‚¹å‡»åœ°å€æ å·¦ä¾§çš„é”å›¾æ ‡ â†’ éº¦å…‹é£ â†’ å…è®¸');
      return;
    }

    // å¦‚æœæƒé™æœªçŸ¥æˆ–æœªæˆäºˆï¼Œå°è¯•è¯·æ±‚æƒé™
    if (microphonePermission !== 'granted') {
      const permissionGranted = await requestMicrophonePermission();
      if (!permissionGranted) {
        return;
      }
    }

    try {
      setError('');
      
      // æ™ºèƒ½é¢„çƒ­ï¼šç”¨æˆ·å¼€å§‹å½•éŸ³æ—¶é¢„çƒ­è¯­éŸ³åŠ©æ‰‹ç›¸å…³å‡½æ•°
      smartWarmup('voice-assistant');
      
      audioRecorderRef.current.startRecording();
    } catch (error) {
      console.error('å¯åŠ¨å½•éŸ³å¤±è´¥:', error);
      setError(`å¯åŠ¨å½•éŸ³å¤±è´¥: ${error.message}`);
    }
  };

  const handleStopRecording = () => {
    if (audioRecorderRef.current && isRecording) {
      audioRecorderRef.current.stopRecording();
    }
  };

  const handleConnect = () => {
    setIsConnected(true);
    setStatus('connected');
  };

  const handleDisconnect = () => {
    setIsConnected(false);
    setIsRecording(false);
    setStatus('disconnected');
  };

  // æ–‡æœ¬è½¬è¯­éŸ³å¤„ç† - æ”¯æŒç¼“å­˜çš„TTS
  const handleTextToSpeech = async (text, messageId = null, voiceOverride = null) => {
    if (!text || text.trim().length === 0) return;
    
    setIsPlaying(true);
    if (messageId) {
      setReplayingMessageId(messageId);
    }
    console.log('ğŸ”Š å¼€å§‹TTSè¯­éŸ³åˆæˆ:', text.substring(0, 50) + (text.length > 50 ? '...' : ''));
    
    try {
      // æ›´æ–°æ´»åŠ¨æ—¶é—´æˆ³
      updateActivity();
      
      // ä½¿ç”¨ç”¨æˆ·é€‰æ‹©çš„å£°éŸ³è®¾ç½®
      const ttsSettings = ttsConfig.scenarios.conversation;
      const voice = voiceOverride || currentVoice;
      const speed = ttsSettings.speed;
      const model = ttsSettings.model;
      
      // é¦–å…ˆæ£€æŸ¥ç¼“å­˜
      const cachedAudio = getCachedTTS(text, voice, speed, model);
      if (cachedAudio) {
        console.log('ğŸ¯ ä½¿ç”¨ç¼“å­˜çš„TTSéŸ³é¢‘');
        
        // æ’­æ”¾ç¼“å­˜çš„éŸ³é¢‘
        const audioData = `data:audio/mp3;base64,${cachedAudio}`;
        const audio = new Audio(audioData);
        
        audio.onended = () => {
          setIsPlaying(false);
          setReplayingMessageId(null);
          console.log('ğŸ”Š ç¼“å­˜TTSæ’­æ”¾å®Œæˆ');
        };
        
        audio.onerror = (error) => {
          console.error('ç¼“å­˜éŸ³é¢‘æ’­æ”¾å¤±è´¥:', error);
          setIsPlaying(false);
          setReplayingMessageId(null);
        };

        await audio.play();
        return;
      }
      
      // ç¼“å­˜æœªå‘½ä¸­ï¼Œè°ƒç”¨äº‘å‡½æ•°TTS
      console.log('ğŸ’« ç¼“å­˜æœªå‘½ä¸­ï¼Œè°ƒç”¨äº‘å‡½æ•°TTS');
      const app = getApp();
      
      const result = await app.callFunction({
        name: 'text-to-speech',
        data: {
          text: text,
          voice: voice,
          speed: speed,
          format: ttsConfig.default.format,
          model: model
        },
        timeout: 30000 // TTSä¸€èˆ¬æ¯”è¾ƒå¿«ï¼Œ30ç§’è¶…æ—¶è¶³å¤Ÿ
      });

      if (result.result && result.result.success && result.result.audio) {
        console.log('âœ… äº‘å‡½æ•°TTSæˆåŠŸï¼ŒéŸ³é¢‘é•¿åº¦:', result.result.audio.length);
        
        // ç¼“å­˜TTSç»“æœ
        cacheTTS(text, voice, speed, model, result.result.audio);
        
        // æ’­æ”¾äº‘å‡½æ•°è¿”å›çš„éŸ³é¢‘
        const audioData = `data:audio/mp3;base64,${result.result.audio}`;
        const audio = new Audio(audioData);
        
        audio.onended = () => {
          setIsPlaying(false);
          setReplayingMessageId(null);
          console.log('ğŸ”Š äº‘å‡½æ•°TTSæ’­æ”¾å®Œæˆ');
        };
        
        audio.onerror = (error) => {
          console.error('éŸ³é¢‘æ’­æ”¾å¤±è´¥:', error);
          setIsPlaying(false);
          setReplayingMessageId(null);
        };

        await audio.play();
        return;
      } else {
        const errorInfo = result.result?.error;
        const errorMessage = typeof errorInfo === 'object' 
          ? `${errorInfo.message || 'è¯­éŸ³åˆæˆå¤±è´¥'}\n\nğŸ”§ è§£å†³å»ºè®®:\n${(errorInfo.troubleshooting || []).join('\n')}`
          : (errorInfo || 'è¯­éŸ³åˆæˆæœåŠ¡è¿”å›å¤±è´¥');
        
        console.error('âŒ äº‘å‡½æ•°TTSå¤±è´¥:', errorInfo);
        
        // ç›´æ¥æ˜¾ç¤ºé”™è¯¯ï¼Œä¸ä½¿ç”¨ä»»ä½•é™çº§æœºåˆ¶
        setError(`ğŸ”¥ è¯­éŸ³åˆæˆå¤±è´¥: ${errorMessage}`);
        setIsPlaying(false);
        setReplayingMessageId(null);
        return;
      }
    } catch (error) {
      console.error('ğŸ’¥ äº‘å‡½æ•°TTSè°ƒç”¨å¼‚å¸¸:', error);
      
      // ç›´æ¥æ˜¾ç¤ºé”™è¯¯ï¼Œä¸ä½¿ç”¨ä»»ä½•é™çº§æœºåˆ¶  
      setError(`ğŸ”¥ è¯­éŸ³åˆæˆè°ƒç”¨å¤±è´¥: ${error.message}\n\nè¯·æ£€æŸ¥ç½‘ç»œè¿æ¥å’ŒAPIé…ç½®ã€‚`);
      setIsPlaying(false);
      setReplayingMessageId(null);
    }
  };

  const testAPIConnection = async () => {
    setIsTestingAPI(true);
    setApiTestResult(null);
    
    try {
      console.log('ğŸ” VoiceAssistant: å¼€å§‹APIè¿é€šæ€§æµ‹è¯•...');
      console.log('ğŸ” å½“å‰è®¤è¯çŠ¶æ€:', authState);
      console.log('ğŸ” ç¼“å­˜çš„ç™»å½•çŠ¶æ€:', getCachedLoginState());
      
      const startTime = Date.now();
      
      // æ›´æ–°æ´»åŠ¨æ—¶é—´æˆ³ï¼ˆç§»é™¤é‡å¤çš„è®¤è¯è°ƒç”¨ï¼‰
      updateActivity();
      const app = getApp();
      
      // è°ƒç”¨äº‘å‡½æ•°è¿›è¡ŒAPIæµ‹è¯•ï¼ˆå¢åŠ è¶…æ—¶è®¾ç½®ï¼‰
      const result = await app.callFunction({
        name: 'ai-chat',
        data: {
          messages: [
            {
              role: 'user',
              content: 'Hello, this is an API connectivity test.'
            }
          ],
          userLevel: 'intermediate',
          scenario: 'general',
          model: currentModel
        },
        timeout: 60000 // 60ç§’è¶…æ—¶ï¼Œé€‚åº”é«˜çº§æ¨¡å‹çš„å“åº”æ—¶é—´
      });

      const executionTime = Date.now() - startTime;

      if (result.result && result.result.success) {
        setApiTestResult({
          success: true,
          message: 'APIè¿æ¥æˆåŠŸï¼',
          details: {
            model: currentModel,
            executionTime: result.result.executionTime || executionTime,
            method: result.result.method,
            responseLength: result.result.response?.length || 0
          }
        });
        console.log('âœ… APIæµ‹è¯•æˆåŠŸ');
      } else {
        setApiTestResult({
          success: false,
          message: 'APIè¿æ¥å¤±è´¥',
          error: result.result?.error || 'æœªçŸ¥é”™è¯¯',
          errorType: result.result?.errorType,
          details: {
            model: currentModel,
            executionTime: result.result?.executionTime || executionTime
          }
        });
        console.error('âŒ APIæµ‹è¯•å¤±è´¥:', result.result?.error);
      }
    } catch (error) {
      console.error('ğŸ’¥ APIæµ‹è¯•å¼‚å¸¸:', error);
      setApiTestResult({
        success: false,
        message: 'APIæµ‹è¯•å¼‚å¸¸',
        error: error.message,
        details: {
          model: currentModel
        }
      });
    } finally {
      setIsTestingAPI(false);
    }
  };

  return (
    <div className="min-h-screen bg-gray-900">
      {/* é¡¶éƒ¨å¯¼èˆªæ  */}
      <div className="glass-card sticky top-0 z-50">
        <div className="max-w-6xl mx-auto px-6 py-4">
          <div className="flex items-center justify-between">
            <div className="flex items-center space-x-3">
              <div className="w-10 h-10 bg-gradient-to-br from-orange-500 to-purple-600 rounded-xl flex items-center justify-center">
                <Headphones className="w-6 h-6 text-white" />
              </div>
              <div>
                <h1 className="text-xl font-bold text-white">AIè¯­éŸ³åŠ©æ‰‹</h1>
                <p className="text-sm text-gray-400">æ™ºèƒ½è‹±è¯­å¯¹è¯ç»ƒä¹ </p>
              </div>
            </div>
            <div className="flex items-center space-x-3">
              {/* çŠ¶æ€æŒ‡ç¤ºå™¨ */}
              <div className="flex items-center space-x-2">
                <div className={`w-2 h-2 rounded-full ${
                  authState === 'connected' ? 'bg-green-500' :
                  authState === 'connecting' ? 'bg-yellow-500' :
                  'bg-red-500'
                }`}></div>
                <span className="text-sm text-gray-400">
                  {authState === 'connected' ? 'å·²è¿æ¥' :
                   authState === 'connecting' ? 'è¿æ¥ä¸­' : 'æœªè¿æ¥'}
                </span>
              </div>
              <button
                onClick={() => setShowSettings(!showSettings)}
                className="p-2 rounded-lg glass-card hover:bg-white/20 transition-colors"
              >
                <Settings className="w-5 h-5 text-gray-300" />
              </button>
            </div>
          </div>
        </div>
      </div>

      {/* é”™è¯¯æç¤º */}
      {error && (
        <div className="max-w-6xl mx-auto px-6 mt-4">
          <div className="glass-card bg-red-500/10 border-red-500/30 rounded-xl p-4">
            <div className="flex items-start space-x-3">
              <div className="w-8 h-8 bg-red-500/20 rounded-lg flex items-center justify-center flex-shrink-0">
                <span className="text-red-400 text-lg">âš ï¸</span>
              </div>
              <div className="flex-1">
                <h3 className="font-medium text-red-300 mb-1">æœåŠ¡å¼‚å¸¸</h3>
                <pre className="text-sm text-red-200 whitespace-pre-wrap bg-red-500/10 p-3 rounded-lg">
                  {error}
                </pre>
              </div>
              <button
                onClick={() => setError('')}
                className="text-red-400 hover:text-red-300 text-xl"
              >
                Ã—
              </button>
            </div>
          </div>
        </div>
      )}

      {/* ä¸»è¦å†…å®¹åŒºåŸŸ */}
      <div className="max-w-6xl mx-auto px-6 py-8">
        <div className="grid grid-cols-1 lg:grid-cols-3 gap-8">
          
          {/* å·¦ä¾§ï¼šè¯­éŸ³å½•åˆ¶åŒºåŸŸ */}
          <div className="lg:col-span-2">
            <div className="glass-card rounded-2xl shadow-glow p-8">
              
              {/* å½•éŸ³æŒ‰é’®åŒºåŸŸ */}
              <div className="text-center mb-8">
                <div className="relative inline-block">
                  <button
                    onClick={isRecording ? handleStopRecording : handleStartRecording}
                    disabled={!isSupported || microphonePermission === 'denied'}
                    className={`relative w-32 h-32 rounded-full transition-all duration-300 transform hover:scale-105 btn-enhanced ${
                      isRecording
                        ? 'bg-gradient-to-br from-red-500 to-red-600 shadow-lg shadow-red-500/30'
                        : 'bg-gradient-to-br from-orange-500 to-purple-600 shadow-lg shadow-orange-500/30'
                    } ${!isSupported || microphonePermission === 'denied' ? 'opacity-50 cursor-not-allowed' : 'hover:shadow-xl'}`}
                  >
                    {isRecording ? (
                      <Square className="w-10 h-10 text-white absolute inset-0 m-auto" />
                    ) : (
                      <Mic className="w-10 h-10 text-white absolute inset-0 m-auto" />
                    )}
                    
                    {/* å½•éŸ³åŠ¨ç”»åœ†ç¯ */}
                    {isRecording && (
                      <div className="absolute -inset-3 rounded-full border-3 border-red-400 animate-ping"></div>
                    )}
                  </button>
                </div>
                
                <div className="mt-6">
                  <h2 className="text-xl font-semibold text-white mb-2">
                    {isRecording ? 'æ­£åœ¨å½•éŸ³...' : 'ç‚¹å‡»å¼€å§‹å¯¹è¯'}
                  </h2>
                  <p className="text-gray-400">
                    {isRecording ? 'è¯´å‡ºä½ æƒ³è¦ç»ƒä¹ çš„å†…å®¹ï¼Œç‚¹å‡»åœæ­¢å®Œæˆå½•éŸ³' : 
                     isSupported ? 'ä½¿ç”¨ OpenAI Whisper è¿›è¡Œé«˜ç²¾åº¦è¯­éŸ³è¯†åˆ«' : 
                     'æµè§ˆå™¨ä¸æ”¯æŒéŸ³é¢‘å½•åˆ¶'}
                  </p>
                </div>
              </div>

              {/* å½“å‰è½¬å½•æ˜¾ç¤º */}
              {currentTranscript && (
                <div className="glass-card bg-orange-500/10 border-orange-500/30 rounded-xl p-4 mb-6">
                  <div className="flex items-center space-x-3">
                    <div className="w-8 h-8 bg-orange-500/20 rounded-lg flex items-center justify-center">
                      <Mic className="w-5 h-5 text-orange-400" />
                    </div>
                    <span className="text-orange-200 font-medium">{currentTranscript}</span>
                    {isRecording && <div className="w-2 h-2 bg-orange-500 rounded-full animate-pulse"></div>}
                  </div>
                  
                  {/* å¹¶å‘å¤„ç†è¿›åº¦æ¡ */}
                  {isUsingConcurrentMode && processingProgress > 0 && (
                    <div className="mt-3">
                      <div className="flex justify-between text-xs text-orange-300 mb-1">
                        <span>å¤„ç†è¿›åº¦</span>
                        <span>{Math.round(processingProgress * 100)}%</span>
                      </div>
                      <div className="w-full bg-orange-500/20 rounded-full h-2">
                        <div 
                          className="bg-gradient-to-r from-orange-500 to-yellow-500 h-2 rounded-full transition-all duration-300 ease-out"
                          style={{ width: `${processingProgress * 100}%` }}
                        ></div>
                      </div>
                      {processingStage && (
                        <div className="text-xs text-orange-300 mt-1 opacity-75">
                          é˜¶æ®µ: {processingStage}
                        </div>
                      )}
                    </div>
                  )}
                </div>
              )}

              {/* å¤„ç†çŠ¶æ€æŒ‡ç¤ºå™¨ */}
              {(isProcessingAudio || isAIProcessing || isPlaying) && (
                <div className="space-y-3 mb-6">
                  {isProcessingAudio && (
                    <div className="glass-card bg-orange-500/10 border-orange-500/30 rounded-xl p-4">
                      <div className="flex items-center space-x-3">
                        <div className="w-8 h-8 bg-orange-500/20 rounded-lg flex items-center justify-center">
                          <Brain className="w-5 h-5 text-orange-400" />
                        </div>
                        <span className="text-orange-200 font-medium">æ­£åœ¨è¯†åˆ«è¯­éŸ³...</span>
                        <div className="flex space-x-1">
                          <div className="w-2 h-2 bg-orange-500 rounded-full animate-bounce"></div>
                          <div className="w-2 h-2 bg-orange-500 rounded-full animate-bounce" style={{animationDelay: '0.1s'}}></div>
                          <div className="w-2 h-2 bg-orange-500 rounded-full animate-bounce" style={{animationDelay: '0.2s'}}></div>
                        </div>
                      </div>
                    </div>
                  )}
                  
                  {isAIProcessing && (
                    <div className="glass-card bg-purple-500/10 border-purple-500/30 rounded-xl p-4">
                      <div className="flex items-center space-x-3">
                        <div className="w-8 h-8 bg-purple-500/20 rounded-lg flex items-center justify-center">
                          <Sparkles className="w-5 h-5 text-purple-400" />
                        </div>
                        <span className="text-purple-200 font-medium">AIæ­£åœ¨æ€è€ƒå›å¤...</span>
                        <div className="flex space-x-1">
                          <div className="w-2 h-2 bg-purple-500 rounded-full animate-pulse"></div>
                          <div className="w-2 h-2 bg-purple-500 rounded-full animate-pulse" style={{animationDelay: '0.2s'}}></div>
                          <div className="w-2 h-2 bg-purple-500 rounded-full animate-pulse" style={{animationDelay: '0.4s'}}></div>
                        </div>
                      </div>
                    </div>
                  )}
                  
                  {isPlaying && (
                    <div className="glass-card bg-green-500/10 border-green-500/30 rounded-xl p-4">
                      <div className="flex items-center space-x-3">
                        <div className="w-8 h-8 bg-green-500/20 rounded-lg flex items-center justify-center">
                          <Volume2 className="w-5 h-5 text-green-400" />
                        </div>
                        <span className="text-green-200 font-medium">AIæ­£åœ¨æœ—è¯»å›å¤...</span>
                        <div className="flex space-x-1">
                          <div className="w-2 h-2 bg-green-500 rounded-full animate-bounce"></div>
                          <div className="w-2 h-2 bg-green-500 rounded-full animate-bounce" style={{animationDelay: '0.1s'}}></div>
                          <div className="w-2 h-2 bg-green-500 rounded-full animate-bounce" style={{animationDelay: '0.2s'}}></div>
                        </div>
                      </div>
                    </div>
                  )}
                </div>
              )}

              {/* éŸ³é¢‘å¯è§†åŒ– */}
              <div className="glass-card rounded-xl p-6 h-24 flex items-center justify-center">
                {isRecording ? (
                  <div className="flex items-center space-x-2">
                    {[...Array(8)].map((_, i) => (
                      <div 
                        key={i}
                        className="w-1 bg-orange-500 rounded-full animate-bounce"
                        style={{
                          height: `${Math.random() * 32 + 16}px`,
                          animationDelay: `${i * 0.1}s`
                        }}
                      />
                    ))}
                  </div>
                ) : (
                  <div className="text-gray-400 text-sm">éŸ³é¢‘æ³¢å½¢æ˜¾ç¤º</div>
                )}
              </div>
            </div>
          </div>

          {/* å³ä¾§ï¼šå¯¹è¯è®°å½•å’Œè®¾ç½® */}
          <div className="space-y-6">
            
            {/* å¯¹è¯è®°å½• */}
            <div className="glass-card rounded-2xl shadow-glow p-6">
              <div className="flex items-center justify-between mb-4">
                <div className="flex items-center space-x-2">
                  <MessageCircle className="w-5 h-5 text-gray-300" />
                  <h3 className="font-semibold text-white">å¯¹è¯è®°å½•</h3>
                </div>
                <button
                  onClick={() => setMessages([])}
                  className="text-sm text-gray-400 hover:text-gray-200 transition-colors"
                >
                  æ¸…ç©º
                </button>
              </div>
              
              <div className="space-y-3 max-h-96 overflow-y-auto scrollbar-thin">
                {messages.length === 0 ? (
                  <div className="text-center py-8 text-gray-400">
                    <MessageCircle className="w-12 h-12 mx-auto mb-3 opacity-50" />
                    <p>è¿˜æ²¡æœ‰å¯¹è¯è®°å½•</p>
                    <p className="text-sm">å¼€å§‹å½•éŸ³ä¸AIå¯¹è¯</p>
                  </div>
                ) : (
                  messages.map((message, index) => (
                    <div
                      key={index}
                      className={`flex ${message.type === 'user' ? 'justify-end' : 'justify-start'}`}
                    >
                      <div
                        className={`max-w-[85%] px-4 py-3 rounded-2xl ${
                          message.type === 'user'
                            ? 'bg-gradient-to-r from-orange-500 to-purple-600 text-white rounded-br-md'
                            : 'glass-card text-gray-200 rounded-bl-md'
                        }`}
                      >
                        <p className="text-sm leading-relaxed">{message.content}</p>
                        <div className="flex items-center justify-between mt-2">
                          <div className="flex items-center space-x-2">
                            <span className="text-xs opacity-70">{message.timestamp}</span>
                            {message.type === 'assistant' && (
                              <button
                                onClick={() => handleTextToSpeech(message.content, message.id)}
                                disabled={replayingMessageId === message.id}
                                className={`p-1 rounded-full transition-colors ${
                                  message.type === 'user' 
                                    ? 'hover:bg-white/20 text-white/80' 
                                    : 'hover:bg-white/20 text-gray-300'
                                } ${replayingMessageId === message.id ? 'animate-spin' : ''}`}
                                title="é‡æ–°æ’­æ”¾"
                              >
                                {replayingMessageId === message.id ? (
                                  <RotateCcw className="w-3 h-3" />
                                ) : (
                                  <Volume2 className="w-3 h-3" />
                                )}
                              </button>
                            )}
                          </div>
                          {message.method && (
                            <span className={`text-xs px-2 py-1 rounded-full ${
                              message.method === 'openai-whisper' ? 'bg-orange-600/30 text-orange-300' :
                              message.method === 'External AI' ? 'bg-green-600/30 text-green-300' :
                              'bg-yellow-600/30 text-yellow-300'
                            }`}>
                              {message.method === 'openai-whisper' ? 'ğŸ¯' :
                               message.method === 'External AI' ? 'ğŸ¤–' : 'ğŸ­'}
                            </span>
                          )}
                        </div>
                      </div>
                    </div>
                  ))
                )}
              </div>
            </div>

            {/* è®¾ç½®é¢æ¿ */}
            {showSettings && (
              <div className="glass-card rounded-2xl shadow-glow p-6">
                <h3 className="font-semibold text-white mb-4">AIè®¾ç½®</h3>
                
                <div className="space-y-6">
                  {/* AIæ¨¡å‹é€‰æ‹© */}
                  <div>
                    <label className="block text-sm font-medium text-gray-300 mb-3">AIæ¨¡å‹</label>
                    <div className="space-y-2">
                      {AI_MODELS.map((model) => (
                        <button
                          key={model.value}
                          onClick={() => {
                            setCurrentModel(model.value);
                            localStorage.setItem('ai-model', model.value);
                            window.dispatchEvent(new Event('settingsChanged'));
                          }}
                          className={`w-full p-3 rounded-lg border-2 transition-all text-left btn-enhanced ${
                            currentModel === model.value
                              ? 'border-purple-500/50 bg-purple-500/20'
                              : 'border-white/20 hover:border-white/40'
                          }`}
                        >
                          <div className="flex items-center justify-between">
                            <div>
                              <h4 className="font-medium text-sm text-white">{model.label}</h4>
                              <p className="text-xs text-gray-400">{model.description}</p>
                            </div>
                            {currentModel === model.value && (
                              <div className="w-3 h-3 bg-purple-500 rounded-full flex items-center justify-center">
                                <div className="w-1.5 h-1.5 bg-white rounded-full"></div>
                              </div>
                            )}
                          </div>
                        </button>
                      ))}
                    </div>
                  </div>

                  {/* AIåŠ©æ‰‹å£°éŸ³é€‰æ‹© */}
                  <div>
                    <label className="block text-sm font-medium text-gray-300 mb-3">AIåŠ©æ‰‹å£°éŸ³</label>
                    <div className="grid grid-cols-2 gap-2">
                      {VOICE_OPTIONS.map((voice) => (
                        <div key={voice.value} className="relative">
                          <button
                            onClick={() => {
                              setCurrentVoice(voice.value);
                              localStorage.setItem('ai-voice', voice.value);
                              window.dispatchEvent(new Event('settingsChanged'));
                              // ç›´æ¥æ’­æ”¾è¯•å¬å£°éŸ³ï¼Œä½¿ç”¨æŒ‡å®šçš„å£°éŸ³
                              handleTextToSpeech(`ä½ å¥½ï¼Œè¿™æ˜¯ ${voice.label} çš„å£°éŸ³æµ‹è¯•ã€‚`, `test-${voice.value}`, voice.value);
                            }}
                            disabled={replayingMessageId === `test-${voice.value}`}
                            className={`w-full p-3 rounded-lg border-2 transition-all text-left btn-enhanced ${
                              currentVoice === voice.value
                                ? 'border-orange-500/50 bg-orange-500/20'
                                : 'border-white/20 hover:border-white/40'
                            } ${replayingMessageId === `test-${voice.value}` ? 'opacity-75 cursor-not-allowed' : ''}`}
                          >
                            <div className="flex items-center justify-between">
                              <div>
                                <h4 className="font-medium text-sm text-white">{voice.label}</h4>
                                <p className="text-xs text-gray-400">{voice.description}</p>
                              </div>
                              <div className="flex items-center space-x-2">
                                {replayingMessageId === `test-${voice.value}` && (
                                  <RotateCcw className="w-4 h-4 text-orange-400 animate-spin" />
                                )}
                                {currentVoice === voice.value && (
                                  <div className="w-3 h-3 bg-orange-500 rounded-full flex items-center justify-center">
                                    <div className="w-1.5 h-1.5 bg-white rounded-full"></div>
                                  </div>
                                )}
                              </div>
                            </div>
                          </button>

                        </div>
                      ))}
                    </div>
                  </div>

                  {/* å¤„ç†æ¨¡å¼åˆ‡æ¢ */}
                  <div>
                    <label className="block text-sm font-medium text-gray-300 mb-3">
                      å¤„ç†æ¨¡å¼
                      <span className="text-xs text-gray-400 ml-2">(å®éªŒæ€§åŠŸèƒ½)</span>
                    </label>
                    <div className="flex items-center justify-between p-3 bg-gray-800/50 rounded-lg">
                      <div>
                        <div className="text-sm font-medium text-white">
                          {isUsingConcurrentMode ? 'å¹¶å‘å¤„ç†æ¨¡å¼' : 'ä¼ ç»Ÿä¸²è¡Œæ¨¡å¼'}
                        </div>
                        <div className="text-xs text-gray-400 mt-1">
                          {isUsingConcurrentMode 
                            ? 'æ™ºèƒ½é¢„çƒ­ + æµå¼åé¦ˆï¼Œå“åº”æ›´å¿«' 
                            : 'ä¼ ç»Ÿå¤„ç†æ–¹å¼ï¼Œç¨³å®šå¯é '
                          }
                        </div>
                      </div>
                      <label className="relative inline-flex items-center cursor-pointer">
                        <input
                          type="checkbox"
                          className="sr-only peer"
                          checked={isUsingConcurrentMode}
                          onChange={(e) => setIsUsingConcurrentMode(e.target.checked)}
                        />
                        <div className="w-11 h-6 bg-gray-700 peer-focus:outline-none peer-focus:ring-4 peer-focus:ring-purple-800 rounded-full peer peer-checked:after:translate-x-full peer-checked:after:border-white after:content-[''] after:absolute after:top-[2px] after:left-[2px] after:bg-white after:rounded-full after:h-5 after:w-5 after:transition-all peer-checked:bg-purple-600"></div>
                      </label>
                    </div>
                  </div>

                  {/* å½“å‰è®¾ç½®æ˜¾ç¤º */}
                  <div className="pt-4 border-t border-white/20">
                    <div className="flex items-center justify-between text-sm">
                      <div className="flex items-center space-x-2">
                        <span className="font-medium text-gray-300">å½“å‰:</span>
                        <span className="px-2 py-1 bg-purple-500/30 text-purple-300 rounded">
                          {AI_MODELS.find(m => m.value === currentModel)?.label}
                        </span>
                        <span className="px-2 py-1 bg-orange-500/30 text-orange-300 rounded">
                          {VOICE_OPTIONS.find(v => v.value === currentVoice)?.label}
                        </span>
                      </div>
                    </div>
                  </div>
                </div>
              </div>
            )}

            {/* æƒé™çŠ¶æ€ */}
            <div className="glass-card rounded-2xl shadow-glow p-6">
              <h3 className="font-semibold text-white mb-4">æƒé™çŠ¶æ€</h3>
              
              <div className="space-y-3">
                <div className="flex items-center justify-between">
                  <div className="flex items-center space-x-3">
                    <div className={`w-3 h-3 rounded-full ${
                      microphonePermission === 'granted' ? 'bg-green-500' :
                      microphonePermission === 'denied' ? 'bg-red-500' :
                      'bg-yellow-500'
                    }`}></div>
                    <span className="text-sm text-gray-300">éº¦å…‹é£æƒé™</span>
                  </div>
                  {microphonePermission !== 'granted' && (
                    <button
                      onClick={requestMicrophonePermission}
                      className="text-xs px-3 py-1 bg-gradient-to-r from-orange-500 to-purple-600 hover:from-orange-600 hover:to-purple-700 text-white rounded-full transition-all btn-enhanced"
                    >
                      æˆæƒ
                    </button>
                  )}
                </div>
                
                <div className="flex items-center justify-between">
                  <div className="flex items-center space-x-3">
                    <div className={`w-3 h-3 rounded-full ${
                      isSupported ? 'bg-green-500' : 'bg-red-500'
                    }`}></div>
                    <span className="text-sm text-gray-300">æµè§ˆå™¨æ”¯æŒ</span>
                  </div>
                  <span className="text-xs text-gray-400">
                    {isSupported ? 'Chrome' : 'éœ€è¦Chrome'}
                  </span>
                </div>
              </div>
            </div>
          </div>
        </div>
      </div>
    </div>
  );
};

export default VoiceAssistantPage;